{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea70bce3-b221-436e-957d-7a31537a8e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 메시지는 콘솔과 파일에 동시에 기록됩니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "이 메시지도 로그에 기록됩니다.\n",
      "/usr/local/lib/python3.8/dist-packages/kornia/feature/lightglue.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 256, 256])\n",
      "\u001b[40;93m[Episode Start] Currently using dataset file: ('/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/0801.png',), Episode count: 1\u001b[0m\n",
      "\u001b[92mInitial PSNR: 24.226343 | Time: 09:55:02\n",
      "Initial MSE: 0.003403\u001b[0m\n",
      "Step: 100   \n",
      "PSNR Before: 24.228741 | PSNR After: 24.228695 | Change: -0.000046 | Diff: 0.002352\n",
      "Reward: -0.04 | Success Ratio: 0.170000 | Flip Count: 17\n",
      "Pre-flip Value: 0.606601 | New State Value: 1\n",
      "Flip Pixel: Channel=6, Row=215, Col=181\n",
      "Step: 200   \n",
      "PSNR Before: 24.231823 | PSNR After: 24.231827 | Change: 0.000004 | Diff: 0.005484\n",
      "Reward: 0.00 | Success Ratio: 0.205000 | Flip Count: 41\n",
      "Pre-flip Value: 0.542648 | New State Value: 0\n",
      "Flip Pixel: Channel=0, Row=25, Col=244\n",
      "Step: 300   \n",
      "PSNR Before: 24.234974 | PSNR After: 24.234903 | Change: -0.000071 | Diff: 0.008560\n",
      "Reward: -0.06 | Success Ratio: 0.230000 | Flip Count: 69\n",
      "Pre-flip Value: 0.029821 | New State Value: 0\n",
      "Flip Pixel: Channel=2, Row=71, Col=162\n",
      "Step: 400   \n",
      "PSNR Before: 24.237740 | PSNR After: 24.237690 | Change: -0.000050 | Diff: 0.011347\n",
      "Reward: -0.04 | Success Ratio: 0.235000 | Flip Count: 94\n",
      "Pre-flip Value: 0.285047 | New State Value: 0\n",
      "Flip Pixel: Channel=7, Row=77, Col=100\n",
      "Step: 500   \n",
      "PSNR Before: 24.241600 | PSNR After: 24.241514 | Change: -0.000086 | Diff: 0.015171\n",
      "Reward: -0.07 | Success Ratio: 0.242000 | Flip Count: 121\n",
      "Pre-flip Value: 0.613453 | New State Value: 1\n",
      "Flip Pixel: Channel=3, Row=200, Col=125\n",
      "Step: 600   \n",
      "PSNR Before: 24.245209 | PSNR After: 24.245113 | Change: -0.000095 | Diff: 0.018770\n",
      "Reward: -0.08 | Success Ratio: 0.243333 | Flip Count: 146\n",
      "Pre-flip Value: 0.713608 | New State Value: 1\n",
      "Flip Pixel: Channel=6, Row=137, Col=235\n",
      "Step: 700   \n",
      "PSNR Before: 24.247803 | PSNR After: 24.247574 | Change: -0.000229 | Diff: 0.021231\n",
      "Reward: -0.18 | Success Ratio: 0.232857 | Flip Count: 163\n",
      "Pre-flip Value: 0.999312 | New State Value: 1\n",
      "Flip Pixel: Channel=1, Row=66, Col=190\n",
      "Step: 800   \n",
      "PSNR Before: 24.249779 | PSNR After: 24.249475 | Change: -0.000303 | Diff: 0.023132\n",
      "Reward: -0.24 | Success Ratio: 0.220000 | Flip Count: 176\n",
      "Pre-flip Value: 0.333074 | New State Value: 0\n",
      "Flip Pixel: Channel=7, Row=74, Col=229\n",
      "Step: 900   \n",
      "PSNR Before: 24.251726 | PSNR After: 24.251387 | Change: -0.000340 | Diff: 0.025043\n",
      "Reward: -0.27 | Success Ratio: 0.215556 | Flip Count: 194\n",
      "Pre-flip Value: 0.277852 | New State Value: 0\n",
      "Flip Pixel: Channel=1, Row=45, Col=51\n",
      "Step: 1000  \n",
      "PSNR Before: 24.253571 | PSNR After: 24.253819 | Change: 0.000248 | Diff: 0.027475\n",
      "Reward: 0.20 | Success Ratio: 0.215000 | Flip Count: 215\n",
      "Pre-flip Value: 0.621862 | New State Value: 0\n",
      "Flip Pixel: Channel=7, Row=240, Col=244\n",
      "Step: 1100  \n",
      "PSNR Before: 24.257212 | PSNR After: 24.257318 | Change: 0.000107 | Diff: 0.030975\n",
      "Reward: 0.09 | Success Ratio: 0.216364 | Flip Count: 238\n",
      "Pre-flip Value: 0.747750 | New State Value: 0\n",
      "Flip Pixel: Channel=2, Row=160, Col=73\n",
      "Step: 1200  \n",
      "PSNR Before: 24.258987 | PSNR After: 24.258871 | Change: -0.000116 | Diff: 0.032528\n",
      "Reward: -0.09 | Success Ratio: 0.215000 | Flip Count: 258\n",
      "Pre-flip Value: 0.099946 | New State Value: 0\n",
      "Flip Pixel: Channel=4, Row=179, Col=245\n",
      "Step: 1300  \n",
      "PSNR Before: 24.261345 | PSNR After: 24.261482 | Change: 0.000137 | Diff: 0.035139\n",
      "Reward: 0.11 | Success Ratio: 0.215385 | Flip Count: 280\n",
      "Pre-flip Value: 0.897067 | New State Value: 0\n",
      "Flip Pixel: Channel=6, Row=198, Col=83\n",
      "Step: 1400  \n",
      "PSNR Before: 24.264400 | PSNR After: 24.264183 | Change: -0.000217 | Diff: 0.037840\n",
      "Reward: -0.17 | Success Ratio: 0.217857 | Flip Count: 305\n",
      "Pre-flip Value: 0.065109 | New State Value: 0\n",
      "Flip Pixel: Channel=3, Row=250, Col=151\n",
      "Step: 1500  \n",
      "PSNR Before: 24.267384 | PSNR After: 24.267052 | Change: -0.000332 | Diff: 0.040709\n",
      "Reward: -0.27 | Success Ratio: 0.215333 | Flip Count: 323\n",
      "Pre-flip Value: 0.847344 | New State Value: 1\n",
      "Flip Pixel: Channel=5, Row=161, Col=43\n",
      "Step: 1600  \n",
      "PSNR Before: 24.270645 | PSNR After: 24.270399 | Change: -0.000246 | Diff: 0.044056\n",
      "Reward: -0.20 | Success Ratio: 0.214375 | Flip Count: 343\n",
      "Pre-flip Value: 0.737484 | New State Value: 1\n",
      "Flip Pixel: Channel=5, Row=73, Col=246\n",
      "Step: 1700  \n",
      "PSNR Before: 24.272825 | PSNR After: 24.272821 | Change: -0.000004 | Diff: 0.046478\n",
      "Reward: -0.00 | Success Ratio: 0.212941 | Flip Count: 362\n",
      "Pre-flip Value: 0.183898 | New State Value: 0\n",
      "Flip Pixel: Channel=2, Row=218, Col=211\n",
      "Step: 1800  \n",
      "PSNR Before: 24.275579 | PSNR After: 24.275543 | Change: -0.000036 | Diff: 0.049200\n",
      "Reward: -0.03 | Success Ratio: 0.209444 | Flip Count: 377\n",
      "Pre-flip Value: 0.036784 | New State Value: 0\n",
      "Flip Pixel: Channel=4, Row=255, Col=49\n",
      "Step: 1900  \n",
      "PSNR Before: 24.277697 | PSNR After: 24.277718 | Change: 0.000021 | Diff: 0.051374\n",
      "Reward: 0.02 | Success Ratio: 0.208947 | Flip Count: 397\n",
      "Pre-flip Value: 0.277309 | New State Value: 1\n",
      "Flip Pixel: Channel=2, Row=243, Col=141\n",
      "Step: 2000  \n",
      "PSNR Before: 24.279432 | PSNR After: 24.279375 | Change: -0.000057 | Diff: 0.053032\n",
      "Reward: -0.05 | Success Ratio: 0.209500 | Flip Count: 419\n",
      "Pre-flip Value: 0.006627 | New State Value: 0\n",
      "Flip Pixel: Channel=6, Row=140, Col=0\n",
      "Step: 2100  \n",
      "PSNR Before: 24.282333 | PSNR After: 24.282143 | Change: -0.000191 | Diff: 0.055799\n",
      "Reward: -0.15 | Success Ratio: 0.211905 | Flip Count: 445\n",
      "Pre-flip Value: 0.577330 | New State Value: 1\n",
      "Flip Pixel: Channel=1, Row=165, Col=61\n",
      "Step: 2200  \n",
      "PSNR Before: 24.284632 | PSNR After: 24.284748 | Change: 0.000116 | Diff: 0.058405\n",
      "Reward: 0.09 | Success Ratio: 0.210909 | Flip Count: 464\n",
      "Pre-flip Value: 0.302115 | New State Value: 1\n",
      "Flip Pixel: Channel=5, Row=146, Col=99\n",
      "Step: 2300  \n",
      "PSNR Before: 24.287130 | PSNR After: 24.287033 | Change: -0.000097 | Diff: 0.060690\n",
      "Reward: -0.08 | Success Ratio: 0.207826 | Flip Count: 478\n",
      "Pre-flip Value: 0.000954 | New State Value: 0\n",
      "Flip Pixel: Channel=6, Row=72, Col=66\n",
      "Step: 2400  \n",
      "PSNR Before: 24.290752 | PSNR After: 24.290678 | Change: -0.000074 | Diff: 0.064335\n",
      "Reward: -0.06 | Success Ratio: 0.210000 | Flip Count: 504\n",
      "Pre-flip Value: 0.201852 | New State Value: 0\n",
      "Flip Pixel: Channel=3, Row=113, Col=66\n",
      "Step: 2500  \n",
      "PSNR Before: 24.293419 | PSNR After: 24.293610 | Change: 0.000191 | Diff: 0.067266\n",
      "Reward: 0.15 | Success Ratio: 0.210000 | Flip Count: 525\n",
      "Pre-flip Value: 0.654685 | New State Value: 0\n",
      "Flip Pixel: Channel=3, Row=255, Col=224\n",
      "Step: 2600  \n",
      "PSNR Before: 24.296476 | PSNR After: 24.296610 | Change: 0.000134 | Diff: 0.070267\n",
      "Reward: 0.11 | Success Ratio: 0.210385 | Flip Count: 547\n",
      "Pre-flip Value: 0.576525 | New State Value: 0\n",
      "Flip Pixel: Channel=3, Row=203, Col=201\n",
      "Step: 2700  \n",
      "PSNR Before: 24.298100 | PSNR After: 24.298117 | Change: 0.000017 | Diff: 0.071774\n",
      "Reward: 0.01 | Success Ratio: 0.209259 | Flip Count: 565\n",
      "Pre-flip Value: 0.870391 | New State Value: 0\n",
      "Flip Pixel: Channel=5, Row=171, Col=62\n",
      "Step: 2800  \n",
      "PSNR Before: 24.300587 | PSNR After: 24.300318 | Change: -0.000269 | Diff: 0.073975\n",
      "Reward: -0.22 | Success Ratio: 0.209286 | Flip Count: 586\n",
      "Pre-flip Value: 0.128805 | New State Value: 0\n",
      "Flip Pixel: Channel=3, Row=131, Col=156\n",
      "Step: 2900  \n",
      "PSNR Before: 24.302414 | PSNR After: 24.302519 | Change: 0.000105 | Diff: 0.076176\n",
      "Reward: 0.08 | Success Ratio: 0.210690 | Flip Count: 611\n",
      "Pre-flip Value: 0.708421 | New State Value: 0\n",
      "Flip Pixel: Channel=1, Row=212, Col=46\n",
      "Step: 3000  \n",
      "PSNR Before: 24.305000 | PSNR After: 24.304653 | Change: -0.000347 | Diff: 0.078310\n",
      "Reward: -0.28 | Success Ratio: 0.212000 | Flip Count: 636\n",
      "Pre-flip Value: 0.554147 | New State Value: 1\n",
      "Flip Pixel: Channel=2, Row=39, Col=137\n",
      "Step: 3100  \n",
      "PSNR Before: 24.308159 | PSNR After: 24.308023 | Change: -0.000135 | Diff: 0.081680\n",
      "Reward: -0.11 | Success Ratio: 0.211935 | Flip Count: 657\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=4, Row=7, Col=159\n",
      "Step: 3200  \n",
      "PSNR Before: 24.310829 | PSNR After: 24.310358 | Change: -0.000471 | Diff: 0.084015\n",
      "Reward: -0.38 | Success Ratio: 0.211875 | Flip Count: 678\n",
      "Pre-flip Value: 0.992775 | New State Value: 1\n",
      "Flip Pixel: Channel=2, Row=177, Col=15\n",
      "Step: 3300  \n",
      "PSNR Before: 24.312992 | PSNR After: 24.312685 | Change: -0.000307 | Diff: 0.086342\n",
      "Reward: -0.25 | Success Ratio: 0.210909 | Flip Count: 696\n",
      "Pre-flip Value: 0.833420 | New State Value: 1\n",
      "Flip Pixel: Channel=7, Row=134, Col=148\n",
      "Step: 3400  \n",
      "PSNR Before: 24.315336 | PSNR After: 24.315216 | Change: -0.000120 | Diff: 0.088873\n",
      "Reward: -0.10 | Success Ratio: 0.210000 | Flip Count: 714\n",
      "Pre-flip Value: 0.000969 | New State Value: 0\n",
      "Flip Pixel: Channel=4, Row=187, Col=95\n",
      "Step: 3500  \n",
      "PSNR Before: 24.318016 | PSNR After: 24.317326 | Change: -0.000690 | Diff: 0.090982\n",
      "Reward: -0.55 | Success Ratio: 0.210571 | Flip Count: 737\n",
      "Pre-flip Value: 0.922919 | New State Value: 1\n",
      "Flip Pixel: Channel=6, Row=147, Col=9\n",
      "Step: 3600  \n",
      "PSNR Before: 24.320820 | PSNR After: 24.320316 | Change: -0.000504 | Diff: 0.093973\n",
      "Reward: -0.40 | Success Ratio: 0.208889 | Flip Count: 752\n",
      "Pre-flip Value: 0.452471 | New State Value: 0\n",
      "Flip Pixel: Channel=7, Row=121, Col=181\n",
      "Step: 3700  \n",
      "PSNR Before: 24.324177 | PSNR After: 24.324001 | Change: -0.000175 | Diff: 0.097658\n",
      "Reward: -0.14 | Success Ratio: 0.208378 | Flip Count: 771\n",
      "Pre-flip Value: 0.283495 | New State Value: 0\n",
      "Flip Pixel: Channel=7, Row=96, Col=54\n",
      "Step: 3758   | Time: 09:55:34\n",
      "PSNR Before: 24.325844 | PSNR After: 24.326696 | Change: 0.000853 | Diff: 0.100353\n",
      "Reward: 0.68 | Success Ratio: 0.208089 | Flip Count: 782\n",
      "Pre-flip Value: 1.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=1, Row=206, Col=88\n",
      "Step: 3759   | Time: 09:55:34\n",
      "PSNR Before: 24.326696 | PSNR After: 24.326727 | Change: 0.000031 | Diff: 0.100384\n",
      "Reward: 0.02 | Success Ratio: 0.208300 | Flip Count: 783\n",
      "Pre-flip Value: 0.776856 | New State Value: 0\n",
      "Flip Pixel: Channel=0, Row=75, Col=175\n",
      "Episode 1: Total Reward: -934.4869083437868\n",
      "\u001b[40;93m[Episode Start] Currently using dataset file: ('/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/0802.png',), Episode count: 2\u001b[0m\n",
      "\u001b[92mInitial PSNR: 25.081959 | Time: 09:55:34\n",
      "Initial MSE: 0.002206\u001b[0m\n",
      "Step: 100   \n",
      "PSNR Before: 25.086338 | PSNR After: 25.086367 | Change: 0.000029 | Diff: 0.004408\n",
      "Reward: 0.02 | Success Ratio: 0.290000 | Flip Count: 29\n",
      "Pre-flip Value: 0.636685 | New State Value: 0\n",
      "Flip Pixel: Channel=3, Row=199, Col=49\n",
      "Step: 200   \n",
      "PSNR Before: 25.089731 | PSNR After: 25.089737 | Change: 0.000006 | Diff: 0.007778\n",
      "Reward: 0.00 | Success Ratio: 0.275000 | Flip Count: 55\n",
      "Pre-flip Value: 0.289624 | New State Value: 1\n",
      "Flip Pixel: Channel=3, Row=26, Col=45\n",
      "Step: 300   \n",
      "PSNR Before: 25.093410 | PSNR After: 25.093000 | Change: -0.000410 | Diff: 0.011042\n",
      "Reward: -0.33 | Success Ratio: 0.280000 | Flip Count: 84\n",
      "Pre-flip Value: 0.575714 | New State Value: 1\n",
      "Flip Pixel: Channel=7, Row=105, Col=21\n",
      "Step: 400   \n",
      "PSNR Before: 25.099442 | PSNR After: 25.099478 | Change: 0.000036 | Diff: 0.017519\n",
      "Reward: 0.03 | Success Ratio: 0.307500 | Flip Count: 123\n",
      "Pre-flip Value: 0.014950 | New State Value: 1\n",
      "Flip Pixel: Channel=4, Row=6, Col=171\n",
      "Step: 500   \n",
      "PSNR Before: 25.103228 | PSNR After: 25.102518 | Change: -0.000710 | Diff: 0.020559\n",
      "Reward: -0.57 | Success Ratio: 0.290000 | Flip Count: 145\n",
      "Pre-flip Value: 0.934829 | New State Value: 1\n",
      "Flip Pixel: Channel=6, Row=227, Col=137\n",
      "Step: 600   \n",
      "PSNR Before: 25.107584 | PSNR After: 25.107559 | Change: -0.000025 | Diff: 0.025600\n",
      "Reward: -0.02 | Success Ratio: 0.290000 | Flip Count: 174\n",
      "Pre-flip Value: 0.021368 | New State Value: 0\n",
      "Flip Pixel: Channel=4, Row=200, Col=173\n",
      "Step: 700   \n",
      "PSNR Before: 25.113087 | PSNR After: 25.112429 | Change: -0.000658 | Diff: 0.030470\n",
      "Reward: -0.53 | Success Ratio: 0.298571 | Flip Count: 209\n",
      "Pre-flip Value: 0.276120 | New State Value: 0\n",
      "Flip Pixel: Channel=1, Row=92, Col=217\n",
      "Step: 800   \n",
      "PSNR Before: 25.117226 | PSNR After: 25.116661 | Change: -0.000565 | Diff: 0.034702\n",
      "Reward: -0.45 | Success Ratio: 0.293750 | Flip Count: 235\n",
      "Pre-flip Value: 0.558710 | New State Value: 1\n",
      "Flip Pixel: Channel=0, Row=160, Col=23\n",
      "Step: 900   \n",
      "PSNR Before: 25.123177 | PSNR After: 25.123251 | Change: 0.000074 | Diff: 0.041292\n",
      "Reward: 0.06 | Success Ratio: 0.288889 | Flip Count: 260\n",
      "Pre-flip Value: 0.444553 | New State Value: 1\n",
      "Flip Pixel: Channel=1, Row=62, Col=165\n",
      "Step: 1000  \n",
      "PSNR Before: 25.129269 | PSNR After: 25.129189 | Change: -0.000080 | Diff: 0.047230\n",
      "Reward: -0.06 | Success Ratio: 0.282000 | Flip Count: 282\n",
      "Pre-flip Value: 0.420083 | New State Value: 0\n",
      "Flip Pixel: Channel=1, Row=107, Col=163\n",
      "Step: 1100  \n",
      "PSNR Before: 25.136120 | PSNR After: 25.135704 | Change: -0.000416 | Diff: 0.053745\n",
      "Reward: -0.33 | Success Ratio: 0.283636 | Flip Count: 312\n",
      "Pre-flip Value: 0.598550 | New State Value: 1\n",
      "Flip Pixel: Channel=2, Row=192, Col=62\n",
      "Step: 1200  \n",
      "PSNR Before: 25.140564 | PSNR After: 25.140499 | Change: -0.000065 | Diff: 0.058540\n",
      "Reward: -0.05 | Success Ratio: 0.276667 | Flip Count: 332\n",
      "Pre-flip Value: 0.412654 | New State Value: 0\n",
      "Flip Pixel: Channel=7, Row=146, Col=143\n",
      "Step: 1300  \n",
      "PSNR Before: 25.143223 | PSNR After: 25.142860 | Change: -0.000362 | Diff: 0.060902\n",
      "Reward: -0.29 | Success Ratio: 0.271538 | Flip Count: 353\n",
      "Pre-flip Value: 0.106755 | New State Value: 0\n",
      "Flip Pixel: Channel=2, Row=212, Col=249\n",
      "Step: 1400  \n",
      "PSNR Before: 25.149391 | PSNR After: 25.149336 | Change: -0.000055 | Diff: 0.067377\n",
      "Reward: -0.04 | Success Ratio: 0.272143 | Flip Count: 381\n",
      "Pre-flip Value: 0.803534 | New State Value: 1\n",
      "Flip Pixel: Channel=1, Row=46, Col=57\n",
      "Step: 1500  \n",
      "PSNR Before: 25.153072 | PSNR After: 25.152624 | Change: -0.000448 | Diff: 0.070665\n",
      "Reward: -0.36 | Success Ratio: 0.271333 | Flip Count: 407\n",
      "Pre-flip Value: 0.625717 | New State Value: 1\n",
      "Flip Pixel: Channel=2, Row=238, Col=93\n",
      "Step: 1600  \n",
      "PSNR Before: 25.156612 | PSNR After: 25.156353 | Change: -0.000259 | Diff: 0.074394\n",
      "Reward: -0.21 | Success Ratio: 0.270000 | Flip Count: 432\n",
      "Pre-flip Value: 0.308530 | New State Value: 0\n",
      "Flip Pixel: Channel=3, Row=94, Col=132\n",
      "Step: 1700  \n",
      "PSNR Before: 25.160067 | PSNR After: 25.160175 | Change: 0.000109 | Diff: 0.078217\n",
      "Reward: 0.09 | Success Ratio: 0.267059 | Flip Count: 454\n",
      "Pre-flip Value: 0.870714 | New State Value: 0\n",
      "Flip Pixel: Channel=6, Row=238, Col=176\n",
      "Step: 1800  \n",
      "PSNR Before: 25.164415 | PSNR After: 25.164333 | Change: -0.000082 | Diff: 0.082375\n",
      "Reward: -0.07 | Success Ratio: 0.266111 | Flip Count: 479\n",
      "Pre-flip Value: 0.952273 | New State Value: 1\n",
      "Flip Pixel: Channel=0, Row=83, Col=153\n",
      "Step: 1900  \n",
      "PSNR Before: 25.169256 | PSNR After: 25.169050 | Change: -0.000206 | Diff: 0.087091\n",
      "Reward: -0.16 | Success Ratio: 0.267895 | Flip Count: 509\n",
      "Pre-flip Value: 0.953319 | New State Value: 1\n",
      "Flip Pixel: Channel=0, Row=102, Col=23\n",
      "Step: 2000  \n",
      "PSNR Before: 25.172832 | PSNR After: 25.171623 | Change: -0.001209 | Diff: 0.089664\n",
      "Reward: -0.97 | Success Ratio: 0.268500 | Flip Count: 537\n",
      "Pre-flip Value: 0.694048 | New State Value: 1\n",
      "Flip Pixel: Channel=5, Row=231, Col=97\n",
      "Step: 2100  \n",
      "PSNR Before: 25.178013 | PSNR After: 25.177744 | Change: -0.000269 | Diff: 0.095785\n",
      "Reward: -0.22 | Success Ratio: 0.267619 | Flip Count: 562\n",
      "Pre-flip Value: 0.485710 | New State Value: 0\n",
      "Flip Pixel: Channel=5, Row=33, Col=240\n",
      "Step: 2200  \n",
      "PSNR Before: 25.181017 | PSNR After: 25.180866 | Change: -0.000151 | Diff: 0.098907\n",
      "Reward: -0.12 | Success Ratio: 0.267273 | Flip Count: 588\n",
      "Pre-flip Value: 0.026023 | New State Value: 0\n",
      "Flip Pixel: Channel=4, Row=6, Col=221\n",
      "Step: 2207   | Time: 09:55:53\n",
      "PSNR Before: 25.181322 | PSNR After: 25.181959 | Change: 0.000637 | Diff: 0.100000\n",
      "Reward: 0.51 | Success Ratio: 0.268237 | Flip Count: 592\n",
      "Pre-flip Value: 0.359221 | New State Value: 1\n",
      "Flip Pixel: Channel=2, Row=68, Col=237\n",
      "Step: 2210   | Time: 09:55:53\n",
      "PSNR Before: 25.181959 | PSNR After: 25.182037 | Change: 0.000078 | Diff: 0.100079\n",
      "Reward: 0.06 | Success Ratio: 0.268326 | Flip Count: 593\n",
      "Pre-flip Value: 0.891337 | New State Value: 0\n",
      "Flip Pixel: Channel=2, Row=208, Col=5\n",
      "Episode 2: Total Reward: -573.6673782348723\n",
      "\u001b[40;93m[Episode Start] Currently using dataset file: ('/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/0803.png',), Episode count: 3\u001b[0m\n",
      "\u001b[92mInitial PSNR: 24.374054 | Time: 09:55:53\n",
      "Initial MSE: 0.002694\u001b[0m\n",
      "Step: 100   \n",
      "PSNR Before: 24.378437 | PSNR After: 24.378508 | Change: 0.000071 | Diff: 0.004454\n",
      "Reward: 0.06 | Success Ratio: 0.240000 | Flip Count: 24\n",
      "Pre-flip Value: 0.639607 | New State Value: 0\n",
      "Flip Pixel: Channel=0, Row=251, Col=197\n",
      "Step: 200   \n",
      "PSNR Before: 24.382563 | PSNR After: 24.382610 | Change: 0.000048 | Diff: 0.008556\n",
      "Reward: 0.04 | Success Ratio: 0.250000 | Flip Count: 50\n",
      "Pre-flip Value: 0.490116 | New State Value: 1\n",
      "Flip Pixel: Channel=1, Row=43, Col=110\n",
      "Step: 300   \n",
      "PSNR Before: 24.389042 | PSNR After: 24.388859 | Change: -0.000183 | Diff: 0.014805\n",
      "Reward: -0.15 | Success Ratio: 0.270000 | Flip Count: 81\n",
      "Pre-flip Value: 0.180684 | New State Value: 0\n",
      "Flip Pixel: Channel=2, Row=144, Col=75\n",
      "Step: 400   \n",
      "PSNR Before: 24.393314 | PSNR After: 24.393167 | Change: -0.000147 | Diff: 0.019114\n",
      "Reward: -0.12 | Success Ratio: 0.287500 | Flip Count: 115\n",
      "Pre-flip Value: 0.293637 | New State Value: 0\n",
      "Flip Pixel: Channel=7, Row=201, Col=206\n",
      "Step: 500   \n",
      "PSNR Before: 24.399168 | PSNR After: 24.399113 | Change: -0.000055 | Diff: 0.025059\n",
      "Reward: -0.04 | Success Ratio: 0.288000 | Flip Count: 144\n",
      "Pre-flip Value: 0.730759 | New State Value: 1\n",
      "Flip Pixel: Channel=7, Row=212, Col=204\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 296\u001b[0m\n\u001b[1;32m    293\u001b[0m total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m--> 296\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m \u001b[43mppo_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m    298\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/base_class.py:556\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    538\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[1;32m    543\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/policies.py:365\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(observation) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have passed a tuple to the predict() function instead of a Numpy array or a Dict. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m     )\n\u001b[0;32m--> 365\u001b[0m obs_tensor, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(obs_tensor, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/policies.py:268\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    265\u001b[0m     observation \u001b[38;5;241m=\u001b[39m maybe_transpose(observation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# Dict obs need to be handled separately\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     vectorized_env \u001b[38;5;241m=\u001b[39m is_vectorized_observation(observation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "from utils.logger import setup_logger\n",
    "\n",
    "# 로거 설정\n",
    "log_file = setup_logger()\n",
    "\n",
    "# 테스트 출력\n",
    "print(\"이 메시지는 콘솔과 파일에 동시에 기록됩니다.\")\n",
    "logging.info(\"이 메시지도 로그에 기록됩니다.\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
    "\n",
    "import torchOptics.optics as tt\n",
    "import torchOptics.metrics as tm\n",
    "\n",
    "from env import BinaryHologramEnv\n",
    "\n",
    "IPS = 256  #이미지 픽셀 사이즈\n",
    "CH = 8  #채널\n",
    "rw = 800  #보상\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 현재 날짜와 시간을 가져와 포맷 지정\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self, num_hologram, final='Sigmoid', in_planes=3,\n",
    "                 channels=[32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "                 convReLU=True, convBN=True, poolReLU=True, poolBN=True,\n",
    "                 deconvReLU=True, deconvBN=True):\n",
    "        super(BinaryNet, self).__init__()\n",
    "\n",
    "        def CRB2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            if relu:\n",
    "                layers += [nn.Tanh()]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        def TRB2d(in_channels, out_channels, kernel_size=2, stride=2, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                          kernel_size=2, stride=2, padding=0,\n",
    "                                          bias=True)]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            if relu:\n",
    "                layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        self.enc1_1 = CRB2d(in_planes, channels[0], relu=convReLU, bn=convBN)\n",
    "        self.enc1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.pool1 = CRB2d(channels[0], channels[0], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc2_1 = CRB2d(channels[0], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.enc2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.pool2 = CRB2d(channels[1], channels[1], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc3_1 = CRB2d(channels[1], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.enc3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.pool3 = CRB2d(channels[2], channels[2], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc4_1 = CRB2d(channels[2], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.enc4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.pool4 = CRB2d(channels[3], channels[3], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc5_1 = CRB2d(channels[3], channels[4], relu=convReLU, bn=convBN)\n",
    "        self.enc5_2 = CRB2d(channels[4], channels[4], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv4 = TRB2d(channels[4], channels[3], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec4_1 = CRB2d(channels[4], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.dec4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv3 = TRB2d(channels[3], channels[2], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec3_1 = CRB2d(channels[3], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.dec3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv2 = TRB2d(channels[2], channels[1], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec2_1 = CRB2d(channels[2], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.dec2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv1 = TRB2d(channels[1], channels[0], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec1_1 = CRB2d(channels[1], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.dec1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.classifier = CRB2d(channels[0], num_hologram, relu=False, bn=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "        enc5_2 = self.enc5_2(enc5_1)\n",
    "\n",
    "        deconv4 = self.deconv4(enc5_2)\n",
    "        concat4 = torch.cat((deconv4, enc4_2), dim=1)\n",
    "        dec4_1 = self.dec4_1(concat4)\n",
    "        dec4_2 = self.dec4_2(dec4_1)\n",
    "\n",
    "        deconv3 = self.deconv3(dec4_2)\n",
    "        concat3 = torch.cat((deconv3, enc3_2), dim=1)\n",
    "        dec3_1 = self.dec3_1(concat3)\n",
    "        dec3_2 = self.dec3_2(dec3_1)\n",
    "\n",
    "        deconv2 = self.deconv2(dec3_2)\n",
    "        concat2 = torch.cat((deconv2, enc2_2), dim=1)\n",
    "        dec2_1 = self.dec2_1(concat2)\n",
    "        dec2_2 = self.dec2_2(dec2_1)\n",
    "\n",
    "        deconv1 = self.deconv1(dec2_2)\n",
    "        concat1 = torch.cat((deconv1, enc1_2), dim=1)\n",
    "        dec1_1 = self.dec1_1(concat1)\n",
    "        dec1_2 = self.dec1_2(dec1_1)\n",
    "\n",
    "        # Final classifier\n",
    "        out = self.classifier(dec1_2)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = BinaryNet(num_hologram=CH, in_planes=1, convReLU=False,\n",
    "                  convBN=False, poolReLU=False, poolBN=False,\n",
    "                  deconvReLU=False, deconvBN=False).cuda()\n",
    "test = torch.randn(1, 1, IPS, IPS).cuda()\n",
    "out = model(test)\n",
    "print(out.shape)\n",
    "\n",
    "class Dataset512(Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True, padding=0):\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.meta = meta\n",
    "        self.isTrain = isTrain\n",
    "        self.target_list = sorted(glob.glob(target_dir+'*.png'))\n",
    "        self.center_crop = torchvision.transforms.CenterCrop(IPS)\n",
    "        self.random_crop = torchvision.transforms.RandomCrop((IPS, IPS))\n",
    "        self.padding = padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        target = tt.imread(self.target_list[idx], meta=self.meta, gray=True).unsqueeze(0)\n",
    "        if target.shape[-1] < IPS or target.shape[-2] < IPS:\n",
    "            target = torchvision.transforms.Resize(IPS)(target)\n",
    "        if self.isTrain:\n",
    "            target = self.random_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        else:\n",
    "            target = self.center_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        # 데이터와 파일 경로를 함께 반환\n",
    "        return target, self.target_list[idx]\n",
    "\n",
    "# 에피소드 보상 로깅 콜백\n",
    "class RewardLoggingCallback(BaseCallback):\n",
    "    def __init__(self, verbose=1):\n",
    "        super(RewardLoggingCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []  # 각 에피소드 보상을 저장\n",
    "        self.current_episode_reward = 0  # 현재 에피소드의 보상\n",
    "        self.episode_count = 0  # 에피소드 수를 추적\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # 현재 스텝의 보상을 누적\n",
    "        reward = self.locals[\"rewards\"]\n",
    "        self.current_episode_reward += reward[0]  # 첫 번째 환경의 보상\n",
    "\n",
    "        # 에피소드 종료 처리\n",
    "        if self.locals[\"dones\"][0]:  # 첫 번째 환경에서 에피소드 종료 시\n",
    "            self.episode_rewards.append(self.current_episode_reward)\n",
    "            self.episode_count += 1\n",
    "\n",
    "            if self.verbose > 0:\n",
    "                print(f\"\\033[41mEpisode {self.episode_count}: Total Reward: {self.current_episode_reward:.2f}\\033[0m\")\n",
    "\n",
    "            # 현재 에피소드 보상을 초기화\n",
    "            self.current_episode_reward = 0\n",
    "\n",
    "        return True  # 학습 계속\n",
    "\n",
    "# 학습 종료 콜백\n",
    "class StopOnEpisodeCallback(BaseCallback):\n",
    "    def __init__(self, max_episodes, verbose=1):\n",
    "        super(StopOnEpisodeCallback, self).__init__(verbose)\n",
    "        self.max_episodes = max_episodes\n",
    "        self.episode_count = 0  # 에피소드 수를 추적\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # `dones`이 True일 때마다 에피소드 증가\n",
    "        if self.locals.get(\"dones\") is not None:\n",
    "            self.episode_count += np.sum(self.locals[\"dones\"])  # 에피소드 완료 횟수 추가\n",
    "\n",
    "        if self.episode_count >= self.max_episodes:  # 최대 에피소드 도달 시 학습 종료\n",
    "            print(f\"Stopping training at episode {self.episode_count}\")\n",
    "            return False  # 학습 중단\n",
    "        return True  # 학습 계속\n",
    "\n",
    "batch_size = 1\n",
    "target_dir = 'dataset/'\n",
    "#target_dir = '/nfs/dataset/DIV2K/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "meta = {'wl': (515e-9), 'dx': (7.56e-6, 7.56e-6)}  # 메타 정보\n",
    "padding = 0\n",
    "\n",
    "# Dataset512 클래스 사용\n",
    "train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=False, padding=padding) #센터크롭\n",
    "#train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=True, padding=padding) #랜덤크롭\n",
    "valid_dataset = Dataset512(target_dir=valid_dir, meta=meta, isTrain=False, padding=padding)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# BinaryNet 모델 로드\n",
    "model = BinaryNet(num_hologram=CH, in_planes=1, convReLU=False, convBN=False,\n",
    "                  poolReLU=False, poolBN=False, deconvReLU=False, deconvBN=False).cuda()\n",
    "model.load_state_dict(torch.load('result_v/2024-12-19 20:37:52.499731_pre_reinforce_8_0.002/2024-12-19 20:37:52.499731_pre_reinforce_8_0.002'))\n",
    "model.eval()\n",
    "\n",
    "# 모델 로드\n",
    "ppo_model_path = \"./ppo_MlpPolicy_models/ppo_MlpPolicy_latest.zip\"\n",
    "ppo_model = PPO.load(ppo_model_path)\n",
    "\n",
    "# 환경 생성\n",
    "env = BinaryHologramEnv(\n",
    "    target_function=model,\n",
    "    trainloader=valid_loader,\n",
    "    max_steps=10000,\n",
    "    T_PSNR=30,\n",
    "    T_PSNR_DIFF=0.1\n",
    ")\n",
    "\n",
    "# 결과를 저장할 디렉토리 설정\n",
    "result_dir = \"./results/\"\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "for episode in range(200):  # 200개의 에피소드 실행\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _states = ppo_model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        done = terminated or truncated\n",
    "\n",
    "    print(f\"Episode {episode + 1}: Total Reward: {total_reward}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    result_file = os.path.join(result_dir, f\"episode_{episode + 1}_result.txt\")\n",
    "    with open(result_file, \"w\") as f:\n",
    "        f.write(f\"Episode {episode + 1}: Total Reward: {total_reward}\\n\")\n",
    "        f.write(f\"Info: {info}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beae235-6bbd-4b04-85f3-c5a9d2095abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

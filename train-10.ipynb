{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d42a35-721b-42cd-9c32-b71a76c29e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 메시지는 콘솔과 파일에 동시에 기록됩니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "이 메시지도 로그에 기록됩니다.\n",
      "/usr/local/lib/python3.8/dist-packages/kornia/feature/lightglue.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 256, 256])\n",
      "Warning: PPO model not found at ./10-ppo_MlpPolicy_models/ppo_MlpPolicy_latest.zip. Starting training from scratch.\n",
      "Starting training from scratch.\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "\u001b[40;93m[Episode Start] Currently using dataset file: ('dataset10/0001.png',), Episode count: 1\u001b[0m\n",
      "\u001b[92mInitial PSNR: 25.004539 | Time: 13:11:00\n",
      "Initial MSE: 0.002122\u001b[0m\n",
      "Logging to ./ppo_MultiInputPolicy/PPO_22\n",
      "Step: 100   \n",
      "PSNR Before: 25.008066 | PSNR After: 25.007957 | Change: -0.000109 | Diff: 0.003418\n",
      "Reward: -0.09 | Success Ratio: 0.290000 | Flip Count: 29\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=1, Row=203, Col=34\n",
      "Step: 200   \n",
      "PSNR Before: 25.012396 | PSNR After: 25.012344 | Change: -0.000051 | Diff: 0.007805\n",
      "Reward: -0.04 | Success Ratio: 0.300000 | Flip Count: 60\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=2, Row=29, Col=1\n",
      "Step: 300   \n",
      "PSNR Before: 25.015759 | PSNR After: 25.015772 | Change: 0.000013 | Diff: 0.011232\n",
      "Reward: 0.01 | Success Ratio: 0.303333 | Flip Count: 91\n",
      "Pre-flip Value: 1.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=3, Row=249, Col=247\n",
      "Step: 400   \n",
      "PSNR Before: 25.020693 | PSNR After: 25.021038 | Change: 0.000345 | Diff: 0.016499\n",
      "Reward: 0.28 | Success Ratio: 0.310000 | Flip Count: 124\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=3, Row=204, Col=16\n",
      "Step: 500   \n",
      "PSNR Before: 25.024271 | PSNR After: 25.024258 | Change: -0.000013 | Diff: 0.019718\n",
      "Reward: -0.01 | Success Ratio: 0.304000 | Flip Count: 152\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=5, Row=36, Col=90\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 121 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 4   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "Step: 600   \n",
      "PSNR Before: 25.027100 | PSNR After: 25.026970 | Change: -0.000130 | Diff: 0.022430\n",
      "Reward: -0.10 | Success Ratio: 0.298333 | Flip Count: 179\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=6, Row=55, Col=229\n",
      "Step: 700   \n",
      "PSNR Before: 25.031939 | PSNR After: 25.032028 | Change: 0.000090 | Diff: 0.027489\n",
      "Reward: 0.07 | Success Ratio: 0.294286 | Flip Count: 206\n",
      "Pre-flip Value: 1.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=0, Row=8, Col=97\n",
      "Step: 800   \n",
      "PSNR Before: 25.036892 | PSNR After: 25.036613 | Change: -0.000278 | Diff: 0.032074\n",
      "Reward: -0.22 | Success Ratio: 0.297500 | Flip Count: 238\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=2, Row=126, Col=239\n",
      "Step: 900   \n",
      "PSNR Before: 25.039955 | PSNR After: 25.039810 | Change: -0.000145 | Diff: 0.035271\n",
      "Reward: -0.12 | Success Ratio: 0.284444 | Flip Count: 256\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=0, Row=198, Col=40\n",
      "Step: 1000  \n",
      "PSNR Before: 25.043688 | PSNR After: 25.043821 | Change: 0.000134 | Diff: 0.039282\n",
      "Reward: 0.11 | Success Ratio: 0.281000 | Flip Count: 281\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=5, Row=82, Col=235\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 1024        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002285632 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.001       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.24        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 6.81        |\n",
      "-----------------------------------------\n",
      "Step: 1100  \n",
      "PSNR Before: 25.048630 | PSNR After: 25.048704 | Change: 0.000074 | Diff: 0.044165\n",
      "Reward: 0.06 | Success Ratio: 0.282727 | Flip Count: 311\n",
      "Pre-flip Value: 1.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=3, Row=231, Col=202\n",
      "Step: 1200  \n",
      "PSNR Before: 25.051544 | PSNR After: 25.051825 | Change: 0.000280 | Diff: 0.047285\n",
      "Reward: 0.22 | Success Ratio: 0.283333 | Flip Count: 340\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=4, Row=66, Col=140\n",
      "Step: 1300  \n",
      "PSNR Before: 25.055550 | PSNR After: 25.055302 | Change: -0.000248 | Diff: 0.050762\n",
      "Reward: -0.20 | Success Ratio: 0.283077 | Flip Count: 368\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=3, Row=39, Col=98\n",
      "Step: 1400  \n",
      "PSNR Before: 25.059757 | PSNR After: 25.058613 | Change: -0.001144 | Diff: 0.054073\n",
      "Reward: -0.92 | Success Ratio: 0.285000 | Flip Count: 399\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=0, Row=203, Col=204\n",
      "Step: 1500  \n",
      "PSNR Before: 25.064358 | PSNR After: 25.064545 | Change: 0.000187 | Diff: 0.060005\n",
      "Reward: 0.15 | Success Ratio: 0.283333 | Flip Count: 425\n",
      "Pre-flip Value: 1.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=4, Row=80, Col=235\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 1536         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077918344 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13.2        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.1         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0475      |\n",
      "|    value_loss           | 0.71         |\n",
      "------------------------------------------\n",
      "Step: 1600  \n",
      "PSNR Before: 25.069695 | PSNR After: 25.069502 | Change: -0.000193 | Diff: 0.064962\n",
      "Reward: -0.15 | Success Ratio: 0.285000 | Flip Count: 456\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=6, Row=4, Col=61\n",
      "Step: 1700  \n",
      "PSNR Before: 25.075020 | PSNR After: 25.074718 | Change: -0.000301 | Diff: 0.070179\n",
      "Reward: -0.24 | Success Ratio: 0.287647 | Flip Count: 489\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=3, Row=18, Col=54\n",
      "Step: 1800  \n",
      "PSNR Before: 25.078552 | PSNR After: 25.078514 | Change: -0.000038 | Diff: 0.073975\n",
      "Reward: -0.03 | Success Ratio: 0.286667 | Flip Count: 516\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=2, Row=57, Col=53\n",
      "Step: 1900  \n",
      "PSNR Before: 25.082739 | PSNR After: 25.082699 | Change: -0.000040 | Diff: 0.078159\n",
      "Reward: -0.03 | Success Ratio: 0.287895 | Flip Count: 547\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=1, Row=223, Col=134\n",
      "Step: 2000  \n",
      "PSNR Before: 25.087355 | PSNR After: 25.087410 | Change: 0.000055 | Diff: 0.082870\n",
      "Reward: 0.04 | Success Ratio: 0.290000 | Flip Count: 580\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=0, Row=115, Col=202\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017898671 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.188      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0708     |\n",
      "|    value_loss           | 0.319       |\n",
      "-----------------------------------------\n",
      "Step: 2100  \n",
      "PSNR Before: 25.090290 | PSNR After: 25.090034 | Change: -0.000256 | Diff: 0.085495\n",
      "Reward: -0.20 | Success Ratio: 0.286667 | Flip Count: 602\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=4, Row=3, Col=244\n",
      "Step: 2200  \n",
      "PSNR Before: 25.094124 | PSNR After: 25.094082 | Change: -0.000042 | Diff: 0.089542\n",
      "Reward: -0.03 | Success Ratio: 0.285455 | Flip Count: 628\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=6, Row=158, Col=246\n",
      "Step: 2300  \n",
      "PSNR Before: 25.098995 | PSNR After: 25.098114 | Change: -0.000881 | Diff: 0.093575\n",
      "Reward: -0.70 | Success Ratio: 0.286087 | Flip Count: 658\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=0, Row=148, Col=205\n",
      "Step: 2400  \n",
      "PSNR Before: 25.104267 | PSNR After: 25.104156 | Change: -0.000111 | Diff: 0.099617\n",
      "Reward: -0.09 | Success Ratio: 0.287083 | Flip Count: 689\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=6, Row=238, Col=254\n",
      "Step: 2411   | Time: 13:11:49\n",
      "PSNR Before: 25.104502 | PSNR After: 25.104588 | Change: 0.000086 | Diff: 0.100048\n",
      "Reward: 0.07 | Success Ratio: 0.287433 | Flip Count: 693\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=5, Row=206, Col=203\n",
      "Step: 2418   | Time: 13:11:49\n",
      "PSNR Before: 25.104588 | PSNR After: 25.104761 | Change: 0.000174 | Diff: 0.100222\n",
      "Reward: 0.14 | Success Ratio: 0.287014 | Flip Count: 694\n",
      "Pre-flip Value: 1.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=4, Row=24, Col=175\n",
      "\u001b[40;93m[Episode Start] Currently using dataset file: ('dataset10/0002.png',), Episode count: 2\u001b[0m\n",
      "\u001b[92mInitial PSNR: 24.825766 | Time: 13:11:49\n",
      "Initial MSE: 0.003266\u001b[0m\n",
      "\u001b[41mEpisode 1: Total Reward: -389.04\u001b[0m\n",
      "Step: 100   \n",
      "PSNR Before: 24.830456 | PSNR After: 24.830095 | Change: -0.000360 | Diff: 0.004330\n",
      "Reward: -0.29 | Success Ratio: 0.330000 | Flip Count: 33\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=1, Row=205, Col=253\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.42e+03    |\n",
      "|    ep_rew_mean          | -389        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024926616 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.184      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0839     |\n",
      "|    value_loss           | 0.346       |\n",
      "-----------------------------------------\n",
      "Step: 200   \n",
      "PSNR Before: 24.835781 | PSNR After: 24.835735 | Change: -0.000046 | Diff: 0.009970\n",
      "Reward: -0.04 | Success Ratio: 0.340000 | Flip Count: 68\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=4, Row=71, Col=186\n",
      "Step: 300   \n",
      "PSNR Before: 24.840805 | PSNR After: 24.841087 | Change: 0.000282 | Diff: 0.015322\n",
      "Reward: 0.23 | Success Ratio: 0.350000 | Flip Count: 105\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=4, Row=104, Col=204\n",
      "Step: 400   \n",
      "PSNR Before: 24.843895 | PSNR After: 24.844185 | Change: 0.000290 | Diff: 0.018419\n",
      "Reward: 0.23 | Success Ratio: 0.320000 | Flip Count: 128\n",
      "Pre-flip Value: 1.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=2, Row=37, Col=241\n",
      "Step: 500   \n",
      "PSNR Before: 24.848692 | PSNR After: 24.848806 | Change: 0.000114 | Diff: 0.023041\n",
      "Reward: 0.09 | Success Ratio: 0.318000 | Flip Count: 159\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=6, Row=85, Col=22\n",
      "Step: 600   \n",
      "PSNR Before: 24.852694 | PSNR After: 24.852657 | Change: -0.000036 | Diff: 0.026892\n",
      "Reward: -0.03 | Success Ratio: 0.305000 | Flip Count: 183\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=3, Row=120, Col=65\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.42e+03    |\n",
      "|    ep_rew_mean          | -389        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009283152 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 78.8        |\n",
      "-----------------------------------------\n",
      "Step: 700   \n",
      "PSNR Before: 24.855236 | PSNR After: 24.854757 | Change: -0.000479 | Diff: 0.028992\n",
      "Reward: -0.38 | Success Ratio: 0.294286 | Flip Count: 206\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=5, Row=150, Col=29\n",
      "Step: 800   \n",
      "PSNR Before: 24.861256 | PSNR After: 24.861118 | Change: -0.000137 | Diff: 0.035353\n",
      "Reward: -0.11 | Success Ratio: 0.300000 | Flip Count: 240\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=7, Row=213, Col=210\n",
      "Step: 900   \n",
      "PSNR Before: 24.867002 | PSNR After: 24.867008 | Change: 0.000006 | Diff: 0.041243\n",
      "Reward: 0.00 | Success Ratio: 0.310000 | Flip Count: 279\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=2, Row=90, Col=54\n",
      "Step: 1000  \n",
      "PSNR Before: 24.869740 | PSNR After: 24.869610 | Change: -0.000130 | Diff: 0.043844\n",
      "Reward: -0.10 | Success Ratio: 0.302000 | Flip Count: 302\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=1, Row=114, Col=146\n",
      "Step: 1100  \n",
      "PSNR Before: 24.873018 | PSNR After: 24.873070 | Change: 0.000051 | Diff: 0.047304\n",
      "Reward: 0.04 | Success Ratio: 0.300909 | Flip Count: 331\n",
      "Pre-flip Value: 1.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=0, Row=125, Col=81\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.42e+03   |\n",
      "|    ep_rew_mean          | -389       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 73         |\n",
      "|    total_timesteps      | 3584       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03268885 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -13.2      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.15      |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.101     |\n",
      "|    value_loss           | 0.223      |\n",
      "----------------------------------------\n",
      "Step: 1200  \n",
      "PSNR Before: 24.877831 | PSNR After: 24.877741 | Change: -0.000090 | Diff: 0.051975\n",
      "Reward: -0.07 | Success Ratio: 0.310000 | Flip Count: 372\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=1, Row=235, Col=163\n",
      "Step: 1300  \n",
      "PSNR Before: 24.881783 | PSNR After: 24.881639 | Change: -0.000143 | Diff: 0.055874\n",
      "Reward: -0.11 | Success Ratio: 0.309231 | Flip Count: 402\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=6, Row=134, Col=133\n",
      "Step: 1400  \n",
      "PSNR Before: 24.886000 | PSNR After: 24.885857 | Change: -0.000143 | Diff: 0.060091\n",
      "Reward: -0.11 | Success Ratio: 0.310714 | Flip Count: 435\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=7, Row=185, Col=240\n",
      "Step: 1500  \n",
      "PSNR Before: 24.889587 | PSNR After: 24.889505 | Change: -0.000082 | Diff: 0.063740\n",
      "Reward: -0.07 | Success Ratio: 0.314000 | Flip Count: 471\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=5, Row=36, Col=12\n",
      "Step: 1600  \n",
      "PSNR Before: 24.893009 | PSNR After: 24.893129 | Change: 0.000120 | Diff: 0.067364\n",
      "Reward: 0.10 | Success Ratio: 0.312500 | Flip Count: 500\n",
      "Pre-flip Value: 1.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=4, Row=128, Col=21\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.42e+03    |\n",
      "|    ep_rew_mean          | -389        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035488844 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.197      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.104      |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "Step: 1700  \n",
      "PSNR Before: 24.896332 | PSNR After: 24.896282 | Change: -0.000050 | Diff: 0.070517\n",
      "Reward: -0.04 | Success Ratio: 0.311176 | Flip Count: 529\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=3, Row=32, Col=70\n",
      "Step: 1800  \n",
      "PSNR Before: 24.899765 | PSNR After: 24.900013 | Change: 0.000248 | Diff: 0.074247\n",
      "Reward: 0.20 | Success Ratio: 0.311667 | Flip Count: 561\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=6, Row=223, Col=138\n",
      "Step: 1900  \n",
      "PSNR Before: 24.902838 | PSNR After: 24.902702 | Change: -0.000135 | Diff: 0.076937\n",
      "Reward: -0.11 | Success Ratio: 0.310526 | Flip Count: 590\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=4, Row=117, Col=121\n",
      "Step: 2000  \n",
      "PSNR Before: 24.905766 | PSNR After: 24.905998 | Change: 0.000233 | Diff: 0.080233\n",
      "Reward: 0.19 | Success Ratio: 0.310000 | Flip Count: 620\n",
      "Pre-flip Value: 1.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=7, Row=175, Col=163\n",
      "Step: 2100  \n",
      "PSNR Before: 24.909304 | PSNR After: 24.909370 | Change: 0.000067 | Diff: 0.083605\n",
      "Reward: 0.05 | Success Ratio: 0.308095 | Flip Count: 647\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=4, Row=27, Col=8\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.42e+03   |\n",
      "|    ep_rew_mean          | -389       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 47         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 96         |\n",
      "|    total_timesteps      | 4608       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03754816 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -13.2      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.22      |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.104     |\n",
      "|    value_loss           | 0.141      |\n",
      "----------------------------------------\n",
      "Step: 2200  \n",
      "PSNR Before: 24.911335 | PSNR After: 24.911465 | Change: 0.000130 | Diff: 0.085699\n",
      "Reward: 0.10 | Success Ratio: 0.305455 | Flip Count: 672\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=3, Row=165, Col=64\n",
      "Step: 2300  \n",
      "PSNR Before: 24.915506 | PSNR After: 24.915350 | Change: -0.000156 | Diff: 0.089584\n",
      "Reward: -0.13 | Success Ratio: 0.307826 | Flip Count: 708\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=7, Row=51, Col=251\n",
      "Step: 2400  \n",
      "PSNR Before: 24.919092 | PSNR After: 24.918797 | Change: -0.000296 | Diff: 0.093031\n",
      "Reward: -0.24 | Success Ratio: 0.305833 | Flip Count: 734\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=6, Row=42, Col=222\n",
      "Step: 2500  \n",
      "PSNR Before: 24.923151 | PSNR After: 24.923222 | Change: 0.000071 | Diff: 0.097456\n",
      "Reward: 0.06 | Success Ratio: 0.304800 | Flip Count: 762\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=4, Row=110, Col=240\n",
      "Step: 2570   | Time: 13:12:47\n",
      "PSNR Before: 24.925482 | PSNR After: 24.925938 | Change: 0.000456 | Diff: 0.100172\n",
      "Reward: 0.36 | Success Ratio: 0.306615 | Flip Count: 788\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=7, Row=134, Col=23\n",
      "Step: 2571   | Time: 13:12:47\n",
      "PSNR Before: 24.925938 | PSNR After: 24.925985 | Change: 0.000048 | Diff: 0.100220\n",
      "Reward: 0.04 | Success Ratio: 0.306884 | Flip Count: 789\n",
      "Pre-flip Value: 0.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=5, Row=56, Col=64\n",
      "\u001b[40;93m[Episode Start] Currently using dataset file: ('dataset10/0003.png',), Episode count: 3\u001b[0m\n",
      "\u001b[92mInitial PSNR: 22.800480 | Time: 13:12:47\n",
      "Initial MSE: 0.004765\u001b[0m\n",
      "\u001b[41mEpisode 2: Total Reward: -293.22\u001b[0m\n",
      "Step: 100   \n",
      "PSNR Before: 22.802839 | PSNR After: 22.802631 | Change: -0.000208 | Diff: 0.002151\n",
      "Reward: -0.17 | Success Ratio: 0.170000 | Flip Count: 17\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=6, Row=250, Col=81\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.49e+03   |\n",
      "|    ep_rew_mean          | -341       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 47         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 108        |\n",
      "|    total_timesteps      | 5120       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03849774 |\n",
      "|    clip_fraction        | 0.386      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -13.2      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.236     |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.108     |\n",
      "|    value_loss           | 0.158      |\n",
      "----------------------------------------\n",
      "Step: 200   \n",
      "PSNR Before: 22.805019 | PSNR After: 22.804794 | Change: -0.000225 | Diff: 0.004314\n",
      "Reward: -0.18 | Success Ratio: 0.180000 | Flip Count: 36\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=6, Row=113, Col=161\n",
      "Step: 300   \n",
      "PSNR Before: 22.806414 | PSNR After: 22.806395 | Change: -0.000019 | Diff: 0.005915\n",
      "Reward: -0.02 | Success Ratio: 0.163333 | Flip Count: 49\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=7, Row=44, Col=171\n",
      "Step: 400   \n",
      "PSNR Before: 22.809212 | PSNR After: 22.808987 | Change: -0.000225 | Diff: 0.008507\n",
      "Reward: -0.18 | Success Ratio: 0.172500 | Flip Count: 69\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=1, Row=12, Col=155\n",
      "Step: 500   \n",
      "PSNR Before: 22.813595 | PSNR After: 22.813477 | Change: -0.000118 | Diff: 0.012997\n",
      "Reward: -0.09 | Success Ratio: 0.180000 | Flip Count: 90\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=3, Row=125, Col=110\n",
      "Step: 600   \n",
      "PSNR Before: 22.815731 | PSNR After: 22.815105 | Change: -0.000626 | Diff: 0.014626\n",
      "Reward: -0.50 | Success Ratio: 0.180000 | Flip Count: 108\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=5, Row=46, Col=6\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49e+03    |\n",
      "|    ep_rew_mean          | -341        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 47          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 5632        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017336775 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "Step: 700   \n",
      "PSNR Before: 22.819271 | PSNR After: 22.819054 | Change: -0.000217 | Diff: 0.018574\n",
      "Reward: -0.17 | Success Ratio: 0.185714 | Flip Count: 130\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=3, Row=220, Col=118\n",
      "Step: 800   \n",
      "PSNR Before: 22.821951 | PSNR After: 22.821667 | Change: -0.000284 | Diff: 0.021187\n",
      "Reward: -0.23 | Success Ratio: 0.183750 | Flip Count: 147\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=0, Row=173, Col=152\n",
      "Step: 900   \n",
      "PSNR Before: 22.823261 | PSNR After: 22.822964 | Change: -0.000298 | Diff: 0.022484\n",
      "Reward: -0.24 | Success Ratio: 0.180000 | Flip Count: 162\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=6, Row=2, Col=166\n",
      "Step: 1000  \n",
      "PSNR Before: 22.826864 | PSNR After: 22.826662 | Change: -0.000202 | Diff: 0.026182\n",
      "Reward: -0.16 | Success Ratio: 0.188000 | Flip Count: 188\n",
      "Pre-flip Value: 1.000000 | New State Value: 1\n",
      "Flip Pixel: Channel=3, Row=34, Col=212\n",
      "Step: 1100  \n",
      "PSNR Before: 22.830479 | PSNR After: 22.830116 | Change: -0.000362 | Diff: 0.029636\n",
      "Reward: -0.29 | Success Ratio: 0.193636 | Flip Count: 213\n",
      "Pre-flip Value: 0.000000 | New State Value: 0\n",
      "Flip Pixel: Channel=1, Row=88, Col=231\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49e+03    |\n",
      "|    ep_rew_mean          | -341        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033717427 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0182      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.106      |\n",
      "|    value_loss           | 0.838       |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "from utils.logger import setup_logger\n",
    "\n",
    "# 로거 설정\n",
    "log_file = setup_logger()\n",
    "\n",
    "# 테스트 출력\n",
    "print(\"이 메시지는 콘솔과 파일에 동시에 기록됩니다.\")\n",
    "logging.info(\"이 메시지도 로그에 기록됩니다.\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
    "\n",
    "import torchOptics.optics as tt\n",
    "import torchOptics.metrics as tm\n",
    "\n",
    "from env import BinaryHologramEnv\n",
    "\n",
    "IPS = 256  #이미지 픽셀 사이즈\n",
    "CH = 8  #채널\n",
    "rw = 800  #보상\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 현재 날짜와 시간을 가져와 포맷 지정\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "class BinaryNet(nn.Module):\n",
    "    def __init__(self, num_hologram, final='Sigmoid', in_planes=3,\n",
    "                 channels=[32, 64, 128, 256, 512, 1024, 2048, 4096],\n",
    "                 convReLU=True, convBN=True, poolReLU=True, poolBN=True,\n",
    "                 deconvReLU=True, deconvBN=True):\n",
    "        super(BinaryNet, self).__init__()\n",
    "\n",
    "        def CRB2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            if relu:\n",
    "                layers += [nn.Tanh()]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        def TRB2d(in_channels, out_channels, kernel_size=2, stride=2, bias=True, relu=True, bn=True):\n",
    "            layers = []\n",
    "            layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                          kernel_size=2, stride=2, padding=0,\n",
    "                                          bias=True)]\n",
    "            if bn:\n",
    "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            if relu:\n",
    "                layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)  # *으로 list unpacking\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        self.enc1_1 = CRB2d(in_planes, channels[0], relu=convReLU, bn=convBN)\n",
    "        self.enc1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.pool1 = CRB2d(channels[0], channels[0], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc2_1 = CRB2d(channels[0], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.enc2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.pool2 = CRB2d(channels[1], channels[1], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc3_1 = CRB2d(channels[1], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.enc3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.pool3 = CRB2d(channels[2], channels[2], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc4_1 = CRB2d(channels[2], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.enc4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.pool4 = CRB2d(channels[3], channels[3], stride=2, relu=poolReLU, bn=poolBN)\n",
    "\n",
    "        self.enc5_1 = CRB2d(channels[3], channels[4], relu=convReLU, bn=convBN)\n",
    "        self.enc5_2 = CRB2d(channels[4], channels[4], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv4 = TRB2d(channels[4], channels[3], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec4_1 = CRB2d(channels[4], channels[3], relu=convReLU, bn=convBN)\n",
    "        self.dec4_2 = CRB2d(channels[3], channels[3], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv3 = TRB2d(channels[3], channels[2], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec3_1 = CRB2d(channels[3], channels[2], relu=convReLU, bn=convBN)\n",
    "        self.dec3_2 = CRB2d(channels[2], channels[2], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv2 = TRB2d(channels[2], channels[1], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec2_1 = CRB2d(channels[2], channels[1], relu=convReLU, bn=convBN)\n",
    "        self.dec2_2 = CRB2d(channels[1], channels[1], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.deconv1 = TRB2d(channels[1], channels[0], relu=deconvReLU, bn=deconvBN, stride=2)\n",
    "        self.dec1_1 = CRB2d(channels[1], channels[0], relu=convReLU, bn=convBN)\n",
    "        self.dec1_2 = CRB2d(channels[0], channels[0], relu=convReLU, bn=convBN)\n",
    "\n",
    "        self.classifier = CRB2d(channels[0], num_hologram, relu=False, bn=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "        enc5_2 = self.enc5_2(enc5_1)\n",
    "\n",
    "        deconv4 = self.deconv4(enc5_2)\n",
    "        concat4 = torch.cat((deconv4, enc4_2), dim=1)\n",
    "        dec4_1 = self.dec4_1(concat4)\n",
    "        dec4_2 = self.dec4_2(dec4_1)\n",
    "\n",
    "        deconv3 = self.deconv3(dec4_2)\n",
    "        concat3 = torch.cat((deconv3, enc3_2), dim=1)\n",
    "        dec3_1 = self.dec3_1(concat3)\n",
    "        dec3_2 = self.dec3_2(dec3_1)\n",
    "\n",
    "        deconv2 = self.deconv2(dec3_2)\n",
    "        concat2 = torch.cat((deconv2, enc2_2), dim=1)\n",
    "        dec2_1 = self.dec2_1(concat2)\n",
    "        dec2_2 = self.dec2_2(dec2_1)\n",
    "\n",
    "        deconv1 = self.deconv1(dec2_2)\n",
    "        concat1 = torch.cat((deconv1, enc1_2), dim=1)\n",
    "        dec1_1 = self.dec1_1(concat1)\n",
    "        dec1_2 = self.dec1_2(dec1_1)\n",
    "\n",
    "        # Final classifier\n",
    "        out = self.classifier(dec1_2)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = BinaryNet(num_hologram=CH, in_planes=1, convReLU=False,\n",
    "                  convBN=False, poolReLU=False, poolBN=False,\n",
    "                  deconvReLU=False, deconvBN=False).cuda()\n",
    "test = torch.randn(1, 1, IPS, IPS).cuda()\n",
    "out = model(test)\n",
    "print(out.shape)\n",
    "\n",
    "class Dataset512(Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True, padding=0):\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.meta = meta\n",
    "        self.isTrain = isTrain\n",
    "        self.target_list = sorted(glob.glob(target_dir+'*.png'))\n",
    "        self.center_crop = torchvision.transforms.CenterCrop(IPS)\n",
    "        self.random_crop = torchvision.transforms.RandomCrop((IPS, IPS))\n",
    "        self.padding = padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        target = tt.imread(self.target_list[idx], meta=self.meta, gray=True).unsqueeze(0)\n",
    "        if target.shape[-1] < IPS or target.shape[-2] < IPS:\n",
    "            target = torchvision.transforms.Resize(IPS)(target)\n",
    "        if self.isTrain:\n",
    "            target = self.random_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        else:\n",
    "            target = self.center_crop(target)\n",
    "            target = torchvision.transforms.functional.pad(target, (self.padding, self.padding, self.padding, self.padding))\n",
    "        # 데이터와 파일 경로를 함께 반환\n",
    "        return target, self.target_list[idx]\n",
    "\n",
    "# 에피소드 보상 로깅 콜백\n",
    "class RewardLoggingCallback(BaseCallback):\n",
    "    def __init__(self, verbose=1):\n",
    "        super(RewardLoggingCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []  # 각 에피소드 보상을 저장\n",
    "        self.current_episode_reward = 0  # 현재 에피소드의 보상\n",
    "        self.episode_count = 0  # 에피소드 수를 추적\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # 현재 스텝의 보상을 누적\n",
    "        reward = self.locals[\"rewards\"]\n",
    "        self.current_episode_reward += reward[0]  # 첫 번째 환경의 보상\n",
    "\n",
    "        # 에피소드 종료 처리\n",
    "        if self.locals[\"dones\"][0]:  # 첫 번째 환경에서 에피소드 종료 시\n",
    "            self.episode_rewards.append(self.current_episode_reward)\n",
    "            self.episode_count += 1\n",
    "\n",
    "            if self.verbose > 0:\n",
    "                print(f\"\\033[41mEpisode {self.episode_count}: Total Reward: {self.current_episode_reward:.2f}\\033[0m\")\n",
    "\n",
    "            # 현재 에피소드 보상을 초기화\n",
    "            self.current_episode_reward = 0\n",
    "\n",
    "        return True  # 학습 계속\n",
    "\n",
    "# 학습 종료 콜백\n",
    "class StopOnEpisodeCallback(BaseCallback):\n",
    "    def __init__(self, max_episodes, verbose=1):\n",
    "        super(StopOnEpisodeCallback, self).__init__(verbose)\n",
    "        self.max_episodes = max_episodes\n",
    "        self.episode_count = 0  # 에피소드 수를 추적\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # `dones`이 True일 때마다 에피소드 증가\n",
    "        if self.locals.get(\"dones\") is not None:\n",
    "            self.episode_count += np.sum(self.locals[\"dones\"])  # 에피소드 완료 횟수 추가\n",
    "\n",
    "        if self.episode_count >= self.max_episodes:  # 최대 에피소드 도달 시 학습 종료\n",
    "            print(f\"Stopping training at episode {self.episode_count}\")\n",
    "            return False  # 학습 중단\n",
    "        return True  # 학습 계속\n",
    "\n",
    "batch_size = 1\n",
    "target_dir = 'dataset10/'\n",
    "#target_dir = '/nfs/dataset/DIV2K/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '/nfs/dataset/DIV2K/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "meta = {'wl': (515e-9), 'dx': (7.56e-6, 7.56e-6)}  # 메타 정보\n",
    "padding = 0\n",
    "\n",
    "# Dataset512 클래스 사용\n",
    "train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=False, padding=padding) #센터크롭\n",
    "#train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=True, padding=padding) #랜덤크롭\n",
    "valid_dataset = Dataset512(target_dir=valid_dir, meta=meta, isTrain=False, padding=padding)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# BinaryNet 모델 로드\n",
    "model = BinaryNet(num_hologram=CH, in_planes=1, convReLU=False, convBN=False,\n",
    "                  poolReLU=False, poolBN=False, deconvReLU=False, deconvBN=False).cuda()\n",
    "model.load_state_dict(torch.load('result_v/2024-12-19 20:37:52.499731_pre_reinforce_8_0.002/2024-12-19 20:37:52.499731_pre_reinforce_8_0.002'))\n",
    "model.eval()\n",
    "\n",
    "# 환경 생성에 새로운 데이터 로더 적용\n",
    "env = BinaryHologramEnv(\n",
    "    target_function=model,\n",
    "    trainloader=train_loader, \n",
    ")\n",
    "\n",
    "# 저장할 폴더 경로 설정\n",
    "save_dir = \"./10-ppo_MlpPolicy_models/\"  # 모델 저장 디렉토리\n",
    "os.makedirs(save_dir, exist_ok=True)  # 디렉토리가 없으면 생성\n",
    "\n",
    "# 모델 저장 경로 설정\n",
    "ppo_model_path = os.path.join(save_dir, \"ppo_MlpPolicy_latest.zip\")  # 최신 PPO 모델 저장 경로\n",
    "resume_training = True  # True로 설정하면 이전 모델에서 학습 재개\n",
    "\n",
    "# PPO 모델 로드 또는 새로 생성\n",
    "if resume_training and os.path.exists(ppo_model_path):\n",
    "    print(f\"Loading trained PPO model from {ppo_model_path}\")\n",
    "    ppo_model = PPO.load(ppo_model_path, env=env)\n",
    "else:\n",
    "    if resume_training:\n",
    "        print(f\"Warning: PPO model not found at {ppo_model_path}. Starting training from scratch.\")\n",
    "    print(\"Starting training from scratch.\")\n",
    "    ppo_model = PPO(\n",
    "        \"MultiInputPolicy\",  # MlpPolicy 대신 MultiInputPolicy 사용\n",
    "        env,\n",
    "        verbose=2,\n",
    "        n_steps=512,\n",
    "        batch_size=128,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.9,\n",
    "        learning_rate=1e-4,\n",
    "        clip_range=0.2,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        ent_coef=0.01,\n",
    "        tensorboard_log=\"./ppo_MultiInputPolicy/\",\n",
    "        #policy_kwargs={\n",
    "        #    \"net_arch\": [dict(pi=[128, 128], vf=[256, 128, 64])],\n",
    "        #},\n",
    "    )\n",
    "\n",
    "# 콜백 설정\n",
    "max_episodes = 8000  # 원하는 에피소드 수\n",
    "reward_logging_callback = RewardLoggingCallback(verbose=1)\n",
    "stop_callback = StopOnEpisodeCallback(max_episodes=max_episodes)\n",
    "callback = CallbackList([reward_logging_callback, stop_callback])\n",
    "\n",
    "# 학습 시작\n",
    "ppo_model.learn(total_timesteps=1000000000, callback=callback)\n",
    "\n",
    "# 모델 저장\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "print(f\"Start {current_date}_model saving at {save_dir}\")\n",
    "ppo_model_save_path = os.path.join(save_dir, f\"ppo_MlpPolicy_{current_date}.zip\")\n",
    "ppo_model.save(ppo_model_save_path)\n",
    "print(f\"PPO Model saved at {save_dir}\")\n",
    "\n",
    "# 최신 모델 업데이트\n",
    "print(f\"Start latest_model updating at {save_dir}\")\n",
    "ppo_model_latest_path = os.path.join(save_dir, \"ppo_MlpPolicy_latest.zip\")\n",
    "\n",
    "# 최신 모델을 덮어쓰기 위해 기존 모델 파일 복사\n",
    "if os.path.exists(ppo_model_latest_path):\n",
    "    os.remove(ppo_model_latest_path)  # 기존 파일 삭제\n",
    "shutil.copyfile(ppo_model_save_path, ppo_model_latest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c92f56-5601-483b-8bcd-7707aa3c8bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
